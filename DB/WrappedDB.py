from DB import DB
import time
import random
import sys
import operator
sys.path.append('../')
from SizedContainerTimeSeriesInterface import SizedContainerTimeSeriesInterface
from TimeSeries import TimeSeries

# READ: Setup for DB
# Download the .zip for portalocker here: https://github.com/WoLpH/portalocker and store it anywhere
# Run python setup.py install

class WrappedDB:

	# This Wrapped DB stores key value pais. If no key is provided it randomly generates a key
	# in the following fashion: TimeStamp+randomNumberBetween0-999.

	def __init__(self, filename, cacheSize=10):
		self.db = DB.connect(filename)
		self.cacheSize = cacheSize
		self.cache = {} # key to TimeSeries dictionary cache
		self.keyToCount = {} # key to number of times TimeSeries has been retrieved

	# Used to inspect the cache of the wrapped DB
	# def dbCache(self):
		# return self.cache

	# Stores a time series by key in the DB
	# Returns the key after storing
	def storeKeyAndTimeSeries(self, timeSeries, key=None):
		if not isinstance(timeSeries, SizedContainerTimeSeriesInterface):
			raise ValueError('Input class is not time series')
		if (key == None):
			# Generate our own key which is current time stamp and a random number from 0 to 999
			key = "{0}-{1}".format(str(time.time())[:10], random.randint(0,999))
			# Check if the autogenerated key was already in the database:
			if (self.getTimeSeriesSize(key) != -1):
				# Generate random keys until we find a key that is not in the database:
				while (true):
					key = "{0}-{1}".format(str(time.time())[:10], random.randint(0,999))
					if (self.getTimeSeriesSize(key == -1)):
						# Unique key found:
							break

		elif (self.getTimeSeriesSize(str(key)) != -1):
			# The key user chose is already in the database. Return Error
			raise ValueError("Key is already in Database")
		else:
			key = str(key)
			
		self.db.set(str(key), self._encode(timeSeries))
		self._storeKeyAndTimeSeriesSize(timeSeries, str(key))
		self.db.commit()
		return key


	# Also stores time series' size in the DB
	def _storeKeyAndTimeSeriesSize(self, timeSeries, key):
		# Note that it is not committed here, and must be committed in the caller function
		self.db.set(str(key) + ':size', str(len(timeSeries)))

	# Get the size of the time series' from its key
	# Returns -1 when time series key does not exist
	def getTimeSeriesSize(self, key):
		try:
			size = self.db.get(str(key) + ':size')
		except KeyError:
			return -1
		return int(self.db.get(str(key) + ':size'))

	# Here we cache the top 10 time series that are accessed the most in memory
	# We store id-count dict in memory 
	# Also store id-timeseries dict in memory
	# Whenever a user calls getTimeSeries, we edit the id-count
	# Grab top 10 ids and counts
	# See if this time series obtained should be in the top 10 cache

	# Returns true if key is in top k cached counts
	def _keyIsInTopCached(self, key):
		topk_keys = sorted(self.keyToCount, key=self.keyToCount.get, reverse=True)[:self.cacheSize]
		# Also make sure that the key is ACTUALLY in the cache
		return (key in topk_keys) and (key in self.cache)

	# Refreshes the cache if necessary - if the new time series key count is greater 
	def _refreshCache(self, key, timeSeries):
		topk_keys = sorted(self.keyToCount, key=self.keyToCount.get, reverse=True)[:self.cacheSize]
		currentKeyCount = self.keyToCount[key] + 1 if key in self.keyToCount else 1
		self.keyToCount[key] = currentKeyCount

		if len(topk_keys) < self.cacheSize:
			# There are less keys in cache than cache size, just store
			self.cache[key] = timeSeries
			return
		
		# Find all the counts in cache, and get the min one
		minKey = ''
		minCount = sys.maxsize
		for k in self.cache:
			if self.keyToCount[k] < minCount:
				minCount = self.keyToCount[k]
				minKey = k

		# Check if the min key's count is less than currentKeyCount
		if currentKeyCount > minCount and not key in self.cache: 
			# Replace the minkey
			del self.cache[minKey]
			self.cache[key] = timeSeries

	# Gets a time series object by key from the DB
	# Returns None when time series key does not exist
	def getTimeSeries(self, key):
		key = str(key)

		timeSeries = None
		# First check if time series at this key is cached
		if self._keyIsInTopCached(key):
			# Get from cache
			timeSeries = self.cache[key]

		try:
			timeSeriesString = self.db.get(key)
		except KeyError:
			return None

		timeSeries = self._decode(timeSeriesString)
		# Refresh cache
		self._refreshCache(key, timeSeries)

		return timeSeries

	# Takes in time series object and transforms it into a string
	def _encode(self, timeSeries):
		items = timeSeries.items()
		encodedTimeSeries = []
		for (time, value) in items:
			encodedTimeSeries.append("(" + str(time) + "," + str(value) + ")")
		return ';'.join(encodedTimeSeries)

	# Takes in encoded time series and transforms it into a TimeSeries object
	# Raise ValueError whenever improper
	def _decode(self, encodedTimeSeries):
		itemStrings = encodedTimeSeries.split(';')
		t = []
		v = []
		for itemString in itemStrings:
			timeValuePair = itemString.split(',')

			if len(timeValuePair) != 2:
				raise ValueError('Time series string is malformed')

			time = timeValuePair[0]
			value = timeValuePair[1]
			if len(time) < 2 or len(value) < 2:
				raise ValueError('Time series string is malformed')			
			
			time = time[1:]
			value = value[:-1]

			# This might throw ValueError if time and value could not be converted to floats
			t.append(float(time))
			v.append(float(value))

		if len(v) == 0 or len(t) == 0:
			raise ValueError('Empty time series passed in')

		z = TimeSeries(values=v, times=t)
		return z
